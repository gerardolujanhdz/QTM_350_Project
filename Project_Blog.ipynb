{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Picturing Paws: Evaluating AI Art**\n",
        "\n",
        "## **Introducing DALL-E**\n",
        "\n",
        "OpenAI's [DALL-E 3](https://openai.com/dall-e-3) serves as a generative AI model that creates images from text prompts. Released natively into ChatGTP Plus and ChatGPT Enterprise, users are able to create images that are both unrestricted to a certain style and open to \"tweaks\" or further edits in order to align it more closely to the intended subject.\n",
        "\n",
        "<br>\n",
        "\n",
        "More specifically, DALL-E \"is a 12-billion parameter version of GPT-3\"...[therefore, like] GPT-3, DALL-E is a transformer language model. It receives both the text and the image as a single stream of data containing up to 1280 tokens (any symbol from a discrete vocabulary), and is trained used maximum likelihood to generate all of the tokens, one after another. This training procedure allows DALL-E to not only generate an image from scratch, but also to regenerate any rectangular region of an existing image that extends to the bottom-right corner, in a way that is consistent with the text prompt\".\n",
        "\n",
        "Thus allowing users to do things such as this!\n",
        "\n",
        "*Insert Picture of Hedgehog*\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Other Cool Capabilities of Generative AI**\n",
        "\n",
        "Extending even beyond still images, a team of publically famous digital animators on YouTube-- Corridor Crew, even managed to transform a live action short film into its equivalant animated doppleganger by asking AI to reconstruct their shots into a more illustrated, comic-esque style. And using this method they managed to produce a full-length short film! Showcasing the potential for Generative AI in creative works.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**Corridor Crew Process**: [Did We Just Change Animation Forever?](https://www.youtube.com/watch?v=_9LX9HSQkWo&ab_channel=CorridorCrew)\n",
        "\n",
        "**Corridor Crew Short Film** [Video Link](https://www.youtube.com/watch?v=GVT3WUa-48Y)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Ethical Concerns**\n",
        "\n",
        "However, Generative AI-- in particular AI generated images, has unintentionally served as an accomplice to copyright infringement cybercrime.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "Generative AI however is associated with concerns revolving [copyright infringement](https://www.copyright.gov/help/faq/faq-definitions.html#:~:text=As%20a%20general%20matter%2C%20copyright,permission%20of%20the%20copyright%20owner.)-- or when a copyrighted work is used without the permission of the respective owner or artist in question. Certain artists for instance have had their work unknowingly entered into databases without consent and in many cases been left without the option to opt out of such practices.\n",
        "\n",
        "<br>\n",
        "\n",
        "In addition to this, the FBI, in an [article](https://timesofindia.indiatimes.com/gadgets-news/scammers-using-ai-to-make-sexually-explicit-content-extort-victims-fbi/articleshow/100856184.cms) releasd earlier this year, has stated that they have \"recieved an increasing number of reports of 'sextortion', a type of extortion tactic wherein criminals trick a victim into providing financial beneifts by threreatening to reveal an explicit or secually-themed photo\"...cybercriminals [are reportedly finding] images of a victim on social media and then [editing] them using AI to make them look realistic and sexually-explicit.\" Thus prompting a newfound concern and need for the general public to exercise caution when posting personal photos online.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "### **Purpose**\n",
        "\n",
        "Taking motivation from these listed issues, we wanted to evaluate DALLE-3's ability to create realistic images by using AWS Rekognition to distinguish between real and AI-generated images.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lAAnn7E9dFTk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmFf1TOk0Wnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to the repository:\n",
        "##**Step 1:** Generate 15 images using [Dog API](https://dog.ceo/dog-api/):\n",
        "#####Fetch random, realistic, different dog breed images\n",
        "\n",
        "This is what the Dog API image will look like:\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1LtrtradSHoSx_76_iRDCBOGp4dZGBJnE' width='250px'>\n",
        "\n",
        "\n",
        "\n",
        "##**Step 2**: Reproduce/Mimic Dog API images with prompt engineering DALL-E 3\n",
        "<br>\n",
        "\n",
        "##### Create text prompts based on the Dog API images to create AI generated images using variable such as breed, color, directionality, actions, mood, etc. (Essentially user describing what you percieve the image to be as)\n",
        "<br>\n",
        "\n",
        "###### **Example prompt** (15 images): Create an image of a groenendael dog. The dog is black. The pov that the picture of the dog is in is facing the dogs right side. The dogs hair should be short.  The dog should have its tongue sticking out just a bit. The dog is standing on a rock with a body of water and sand in the background. The dog is in full frame of the photo. The background is blurry. There is normal lighting.\n",
        "\n",
        "\n",
        "Then generate 15 more images, but with a tweak for better specificity as listed below\n",
        "\n",
        "<br>\n",
        "\n",
        "###### **Tweak:** The dog's body should be in full frame and is sitting on top of the rock. The background is good.\n",
        "#####*This is what a generated tweaked image would look like:*\n",
        "<img src='https://drive.google.com/uc?export=view&id=1G9jcM9wUsdbREGqOJbeG0b2rvK1YK19m' width='250px'>\n",
        "\n",
        "**Quality:**\n",
        "\n",
        "The quality of the Dog API images can vary depending on the source of the API. It iss regularly updated to include new images of dog breeds. Ensuring that users have access to the latest and relevant content.\n",
        "\n",
        "The Dalle-3 images were fairly similar in terms of resolution and quality, however adhereing to what exactly was outlined in the prompts varied, some were addressed and others needed to be repeated in the tweak.\n",
        "\n",
        "<br>\n",
        "\n",
        "##**Step 3:** Create two respective S3 buckets for the Dog API images and prompt engineered images\n",
        "<br>\n",
        "\n",
        "1.   Using AWS open the S3 dashboard and create two separate buckets (for dog API & DALLE-3 respectively)\n",
        "2.   Upload the respective images, either by dragging and dropping or using the upload feature, for each into their buckets\n",
        "\n",
        "<br>\n",
        "\n",
        "##**Step 4:** Sagemaker + Rekognition\n",
        "\n",
        "We used this code in Sagemaker for each image in the bucket:\n"
      ],
      "metadata": {
        "id": "Krnkts4-UoVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "client=boto3.client('rekognition')\n",
        "response = client.detect_labels(Image={'S3Object':{'Bucket':\"ai-pictures-collection\",'Name':\"Aussie.jpg\"}}, MaxLabels=10)\n",
        "response['Labels']\n"
      ],
      "metadata": {
        "id": "27N6PGTUl6en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lack of permission in creating IAM prevented us from doing this as a batch process in Lambda, so it has to be done manually.\n",
        "\n",
        "Essentially the code uses Rekognition to analyze the image in the S3 bucket, and detect labels. The labels are then produced with a confidence score indicating the likelihood the label represents an object or concept in the image. Examples of labels identified are specific dog breeds, nature, and background decor/objects."
      ],
      "metadata": {
        "id": "76WGDBfXl_aT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Architecture Overview**\n",
        "<img src='https://drive.google.com/uc?export=view&id=1tY4cXyk2Iea5922h3YNJAb9to9M0GSie' width='2000px'>\n",
        "\n",
        "\n",
        "\n",
        "First we used Dog API to generate 15 random and realistic images of different dog breeds. Next, we used prompt engineering in DALL-E 3 to generate mimicked versions of the Dog API images by specifying variable such as breed, mood/expression, action, etc and then included a tweak to generate 15 more precise photos. We then sent these images to their respective S3 buckets within the AWS cloud. We ran those buckets through Sagemaker to do a model analysis in rekognition which generated confidence scores between the real and AI images."
      ],
      "metadata": {
        "id": "s4FFuRq5Ulfb"
      }
    }
  ]
}
